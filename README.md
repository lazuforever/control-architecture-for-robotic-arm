Robot AntropomÃ³rfico con Control Multimodal - ROS2
Sistema de control para robot antropomÃ³rfico de 4 grados de libertad que integra visiÃ³n artificial, comandos de voz y planificaciÃ³n de trayectorias mediante ROS2 Humble.
ğŸ¯ DescripciÃ³n General
Este proyecto implementa una arquitectura distribuida en ROS2 para el control de un robot manipulador mediante interacciÃ³n multimodal, combinando:

Comandos de voz a travÃ©s de Amazon Alexa
VisiÃ³n artificial con detecciÃ³n de gestos mediante MediaPipe
PlanificaciÃ³n de trayectorias usando MoveIt2
Control de hardware mediante interfaz personalizada ros2_control

âœ¨ CaracterÃ­sticas Principales

âœ… Interfaz de hardware personalizada para comunicaciÃ³n serial con motores Dynamixel
âœ… DetecciÃ³n de posiciÃ³n de mano en 3D usando MediaPipe Hands
âœ… IntegraciÃ³n con Alexa Skills Kit para control por voz
âœ… PlanificaciÃ³n automÃ¡tica de trayectorias con MoveIt2 y OMPL
âœ… VisualizaciÃ³n en tiempo real en RViz2
âœ… Operaciones Pick & Place mediante gestos

ğŸ—ï¸ Arquitectura del Sistema
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           INTERACCIÃ“N MULTIMODAL                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Alexa Interface â”‚    Finger Detector (VisiÃ³n)  â”‚
â”‚   (Flask + ASK)  â”‚    (MediaPipe + OpenCV)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚
         â–¼                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      Task Server (C++)         â”‚
    â”‚    (Action Server ROS2)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    MoveIt2    â”‚
         â”‚  (Planning)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ros2_control  â”‚
         â”‚  Controller   â”‚
         â”‚    Manager    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Rapling      â”‚
         â”‚  Interface    â”‚
         â”‚  (Hardware)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  ESP32 +      â”‚
         â”‚  Dynamixel    â”‚
         â”‚   AX-12A      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Sistema Operativo y Framework
- **Ubuntu 22.04 LTS** - Plataforma base con soporte hasta 2027
- **ROS2 Humble Hawksbill** - Framework de robÃ³tica distribuida

### Control y PlanificaciÃ³n
- **MoveIt2** - PlanificaciÃ³n de trayectorias y cinemÃ¡tica inversa
- **ros2_control** - Framework de control de hardware
- **OMPL** - LibrerÃ­a de planificaciÃ³n de movimientos
- **Plugin personalizado** - Interfaz de hardware para comunicaciÃ³n serial

### VisiÃ³n Artificial
- **MediaPipe Hands** - DetecciÃ³n de 21 landmarks de mano en tiempo real
- **OpenCV** - Procesamiento de imagen y calibraciÃ³n de cÃ¡mara
- **TF2** - Transformaciones entre sistemas de coordenadas

### InteracciÃ³n de Voz
- **Amazon Alexa Skills Kit** - Procesamiento de comandos de voz
- **Flask** - Servidor web para comunicaciÃ³n con Alexa
- **ngrok** - TÃºnel HTTPS para desarrollo local

### Hardware
- **ESP32** - Microcontrolador dual-core para gestiÃ³n de motores
- **Dynamixel AX-12A** - Servomotores inteligentes con retroalimentaciÃ³n
- **Buffer 74LS241** - AdaptaciÃ³n de seÃ±al half-duplex TTL
- **CÃ¡mara Logitech C920s** - Sensor RGB para visiÃ³n artificial

## ğŸ“¦ Estructura de Paquetes
```
src/
â”œâ”€â”€ rapling_description/       # Modelo URDF del robot
â”‚   â”œâ”€â”€ urdf/                  # Archivos Xacro con geometrÃ­a
â”‚   â”œâ”€â”€ meshes/                # Modelos 3D (STL)
â”‚   â””â”€â”€ launch/                # VisualizaciÃ³n en RViz
â”‚
â”œâ”€â”€ rapling_controller/        # Control de hardware
â”‚   â”œâ”€â”€ include/               # Plugin de interfaz (HPP)
â”‚   â”œâ”€â”€ src/                   # ImplementaciÃ³n serial (CPP)
â”‚   â””â”€â”€ config/                # Controladores y lÃ­mites
â”‚
â”œâ”€â”€ rapling_moveit_2/          # ConfiguraciÃ³n MoveIt2
â”‚   â”œâ”€â”€ config/                # SRDF, cinemÃ¡tica, lÃ­mites
â”‚   â””â”€â”€ launch/                # Move group + RViz
â”‚
â”œâ”€â”€ rapling_remote/            # IntegraciÃ³n multimodal
â”‚   â”œâ”€â”€ alexa_interface.py     # Servidor Flask + Alexa
â”‚   â””â”€â”€ task_server.cpp        # Action server de tareas
â”‚
â”œâ”€â”€ learning_topic/            # VisiÃ³n artificial
â”‚   â”œâ”€â”€ finger_detector.py     # DetecciÃ³n con MediaPipe
â”‚   â””â”€â”€ topic_webcam_pub.py    # Publicador de imagen
â”‚
â””â”€â”€ rapling_msgs/              # Mensajes personalizados
    â””â”€â”€ action/                # DefiniciÃ³n de acciones
```

## ğŸ”§ ImplementaciÃ³n TÃ©cnica

### 1. **Modelo Digital del Robot**
- ExportaciÃ³n desde SolidWorks usando plugin URDF Exporter
- DefiniciÃ³n de 4 articulaciones rotacionales con lÃ­mites
- IntegraciÃ³n con ros2_control mediante tags Xacro
- CalibraciÃ³n de offsets entre cero simulado y cero fÃ­sico

### 2. **Interfaz de Hardware (rapling_controller)**
- Plugin C++ basado en `hardware_interface::SystemInterface`
- ComunicaciÃ³n serial a 115200 baudios con ESP32
- ExportaciÃ³n de `StateInterface` y `CommandInterface` por articulaciÃ³n
- ConversiÃ³n automÃ¡tica radianes â†” grados con compensaciÃ³n de offsets
- PublicaciÃ³n de `JointState` para retroalimentaciÃ³n en tiempo real

### 3. **Sistema de VisiÃ³n (finger_detector)**
- Captura de frames desde `/image_raw` (10 Hz)
- DetecciÃ³n de landmark 8 (punta del Ã­ndice) con MediaPipe
- ConversiÃ³n pÃ­xel â†’ coordenadas 3D usando parÃ¡metros intrÃ­nsecos
- TransformaciÃ³n al frame `world` mediante TF2
- DetecciÃ³n de gesto: mano cerrada + posiciÃ³n estable (3s) = punto guardado
- PublicaciÃ³n de marcadores como `visualization_msgs/MarkerArray`

### 4. **IntegraciÃ³n con Alexa (alexa_interface.py)**
- Servidor Flask en puerto 5000 expuesto mediante ngrok
- Handlers para intents: `LaunchRequest`, `PickIntent`, `WakeIntent`, `SleepIntent`
- SuscripciÃ³n al tÃ³pico `/finger_poses` para obtener coordenadas
- EnvÃ­o de goals al Action Server usando `rclpy.action.ActionClient`
- EjecuciÃ³n en hilo separado para compatibilidad Flask + ROS2 spin

### 5. **Servidor de Tareas (task_server.cpp)**
- Action Server basado en `rclcpp_action`
- RecepciÃ³n de goals con campo `task_number` (0-9)
- Interfaz con MoveIt2 mediante `MoveGroupInterface`
- PlanificaciÃ³n con OMPL y parametrizaciÃ³n temporal IPTP
- EjecuciÃ³n mediante `arm_controller` (JointTrajectoryController)

### 6. **ComunicaciÃ³n Hardware**
- ESP32 con arquitectura dual-core:
  - **Core 0**: Lectura de encoders + envÃ­o de estados
  - **Core 1**: Procesamiento de comandos + control de motores
- Protocolo Dynamixel con daisy-chain en bus compartido
- Control de direcciÃ³n half-duplex mediante GPIO4
- CompensaciÃ³n de motores acoplados (M2A/M2B en hombro)

## ğŸš€ Flujo de OperaciÃ³n

### Ejemplo: Pick & Place con Gestos

1. **Captura de Puntos**
```
   Usuario â†’ Muestra Ã­ndice â†’ MediaPipe detecta â†’ Convierte a 3D
   â†’ Cierra puÃ±o 3s â†’ Guarda punto 1 (Pick)
   â†’ Repite â†’ Guarda punto 2 (Place)
```

2. **Comando de Voz**
```
   Usuario: "Alexa, activar robot"
   Alexa â†’ Flask â†’ Obtiene puntos de /finger_poses
   
   Usuario: "Alexa, ejecutar movimiento"
   Alexa â†’ Flask â†’ EnvÃ­a goal(task_number=1) â†’ Task Server
```

3. **PlanificaciÃ³n y EjecuciÃ³n**
```
   Task Server â†’ MoveIt2 planifica trayectoria
   â†’ Genera waypoints articulares
   â†’ IPTP parametriza tiempos/velocidades
   â†’ arm_controller ejecuta
   â†’ Rapling Interface convierte radâ†’grados+offset
   â†’ ESP32 envÃ­a comandos a Dynamixels
ğŸ“Š Resultados

âœ… ConversiÃ³n precisa entre cero simulado y fÃ­sico de motores
âœ… DetecciÃ³n estable de mano con precisiÃ³n < 30px de desviaciÃ³n
âœ… Trayectorias suaves con perfiles trapezoidales de velocidad
âœ… Tiempo de respuesta < 2s desde comando de voz hasta inicio de movimiento
âœ… SincronizaciÃ³n exitosa entre planificaciÃ³n y hardware real

ğŸ’» Requisitos

Ubuntu 22.04 LTS
ROS2 Humble
Python 3.10+ con: opencv-python, mediapipe, flask, ask-sdk-core
Hardware: ESP32, 4x Dynamixel AX-12A, CÃ¡mara USB, Alexa device

ğŸ“– Uso RÃ¡pido
bash# VisualizaciÃ³n del modelo
ros2 launch rapling_description display.launch.py

# Sistema completo
ros2 launch rapling_controller controller.launch.py
ros2 launch rapling_moveit_2 moveit.launch.py
ros2 launch learning_topic vision_launch.py
python3 src/rapling_remote/alexa_interface.py
ğŸ“ DocumentaciÃ³n
Este proyecto fue desarrollado como trabajo de grado en la Universidad de Pamplona, implementando metodologÃ­as modernas de robÃ³tica distribuida con interacciÃ³n natural persona-robot.
ğŸ“§ Contacto
Brayan Dayani

ğŸ“§ Email: brayandayani@hotmail.com
ğŸ“± TelÃ©fono: +57 312 364 4501
ğŸ“ UbicaciÃ³n: Colombia

Para consultas, sugerencias o colaboraciones sobre el proyecto, no dudes en contactarme.

Desarrollado con ROS2 Humble | MoveIt2 | MediaPipe | Alexa Skills Kit
